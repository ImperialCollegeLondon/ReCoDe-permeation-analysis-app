{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#time-lag-analysis-application","title":"Time Lag Analysis Application","text":"<p>This application provides a user-friendly interface for analysing gas permeation data using the time lag method. Load data from Excel files in <code>data</code>, specify your experimental setup, run the analysis, and visualise the results.</p> <p></p> <p>This exemplar was developed at Imperial College London by Louis Nguyen in collaboration with Dr. Diego Alonso Alvarez from Research Software Engineering and Dr. Chris Cooling from Research Computing &amp; Data Science at the Early Career Researcher Institute.</p>"},{"location":"#learning-outcomes","title":"Learning Outcomes \ud83c\udf93","text":"<p>By using this application, you will:</p> <ul> <li>Gain an understanding of time lag analysis in gas permeation experiments.</li> <li>Learn how to prepare and analyse your experimental data.</li> <li>Get hands-on experience with a GUI for scientific data analysis.</li> <li>Be able to adapt the application to your specific research interests.</li> </ul>"},{"location":"#target-audience","title":"Target Audience \ud83c\udfaf","text":"<p>This exemplar is aimed at researchers, students, and engineers in fields such as Chemical Engineering, Materials Science, and Polymer Science who work with gas or vapor permeation through membranes and films. It is suitable for those who need to:</p> <ul> <li>Analyse experimental permeation data.</li> <li>Understand the principles of the time-lag method.</li> <li>Learn how to implement data analysis workflows in Python.</li> <li>Utilise a graphical user interface for scientific computation.</li> </ul>"},{"location":"#disciplinary-background","title":"Disciplinary Background \ud83d\udd2c","text":"<p>The time-lag method is a widely used experimental technique to determine the diffusion and permeability coefficients of gases or vapours in polymeric membranes. This information is crucial for designing and optimising materials for various applications, such as gas separation, packaging, and protective coatings. This exemplar provides a practical tool and learning resource for performing time-lag analysis, bridging the gap between experimental data acquisition and material property characterisation. It can be useful for researchers in materials science, chemical engineering, polymer chemistry, and any field involving the study of transport phenomena in materials.</p>"},{"location":"#prerequisites","title":"Prerequisites \u2705","text":""},{"location":"#academic","title":"Academic \ud83d\udcda","text":"<ul> <li>Basic understanding of mass transfer principles and gas permeation in materials.</li> <li>Familiarity with data handling (e.g., using spreadsheets like Excel).</li> <li>Some experience with Python programming is beneficial for extending the application or understanding the source code, but not strictly required for using the GUI.</li> </ul>"},{"location":"#system","title":"System \ud83d\udcbb","text":"<ul> <li>Anaconda or Miniconda installed on your system.</li> <li>Git (optional, for cloning the repository).</li> <li>Python 3.12+.</li> </ul>"},{"location":"#software-tools","title":"Software Tools \ud83d\udee0\ufe0f","text":"<ul> <li>Programming language: Python</li> <li>Core libraries:<ul> <li>NumPy: For numerical operations.</li> <li>Pandas: For data manipulation and analysis, especially with Excel files.</li> <li>SciPy: For scientific and technical computing, including curve fitting and optimisation.</li> <li>Matplotlib: For creating static, interactive, and animated visualisations.</li> </ul> </li> <li>GUI: CustomTkinter</li> <li>Environment management: Conda</li> </ul>"},{"location":"#getting-started","title":"Getting Started \ud83d\ude80","text":"<ol> <li> <p>Clone or download the repository:</p> <p><pre><code>git clone https://github.com/ImperialCollegeLondon/ReCoDe-permeation-analysis-app\ncd ReCoDe-permeation-analysis-app\n</code></pre> 2.  Create and activate the <code>permeation-env</code> conda environment:</p> <p><pre><code>conda env create -f environment.yml\nconda activate permeation-env\n</code></pre> 3.  Run the application:</p> <pre><code>python src/app.py\n</code></pre> </li> </ol> <p>The application interface allows you to:</p> <ol> <li>Load data: Use the provided example data or upload your own Excel files from the <code>data</code> directory.</li> <li>Specify parameters: Input your experimental setup details.</li> <li>Run analysis: Click the <code>Run Analysis</code> button to process the data.</li> <li>View results:<ul> <li>Numerical results will appear in the designated text box.</li> <li>Visualisations (plots) will be displayed on the right-hand panel.</li> <li>Save plots using the \"Save\" button located at the top right of the plot area.</li> </ul> </li> </ol>"},{"location":"#data","title":"Data \ud83d\udcca","text":"<p>Example datasets are provided in the <code>data/</code> directory. These are Excel files (<code>.xlsx</code>) representing typical raw data from gas permeation experiments.</p> <ul> <li>Licensing: The provided data may be synthetic or anonymised for demonstration purposes within this exemplar. This data remains the property of the original owner, and permission must be sought for any use outside of this exemplar.</li> <li>Location: Included directly in the repository under the <code>data/</code> folder.</li> </ul>"},{"location":"#documentation-guide","title":"Documentation Guide","text":"<ol> <li>Explore the documentation in the <code>docs</code> folder, starting with <code>01-Home.md</code> and progressing through the guides.</li> <li>Work through the exercises in <code>09-Exercises-and-Best-Practices.md</code>.</li> </ol>"},{"location":"#estimated-time","title":"Estimated Time \u23f3","text":"Task Time Introduction 20 mins Understanding Theoretical Background 30 mins Data Management and Processing 25 mins Time Lag Analysis Implementation 25 mins Python PDE Implementation 25 mins Visualisation Techniques 20 mins GUI Implementation 15 mins Application Workflow 20 mins Subtotal: Core Documentation 3 hours Exercises and Best Practices 3 hours Total Estimated Time 6 hours"},{"location":"#project-structure","title":"Project Structure \ud83d\uddc2\ufe0f","text":"<pre><code>.\n\u251c\u2500\u2500 data/                      # Example Excel data files for demonstration\n\u251c\u2500\u2500 docs/                      # Markdown documentation and guides\n\u2502   \u251c\u2500\u2500 assets/                # Images and other assets for documentation\n\u2502   \u251c\u2500\u2500 01-Home.md\n\u2502   \u251c\u2500\u2500 02-Theoretical-Background.md\n\u2502   \u251c\u2500\u2500 03-Data-Management-and-Processing.md\n\u2502   \u251c\u2500\u2500 04-TimelagAnalysis-Implementation.md\n\u2502   \u251c\u2500\u2500 05-Python-PDE-Implementation.md\n\u2502   \u251c\u2500\u2500 06-Visualisation.md\n\u2502   \u251c\u2500\u2500 07-GUI-Implementation.md\n\u2502   \u251c\u2500\u2500 08-Application-Workflow.md\n\u2502   \u251c\u2500\u2500 09-Exercises-and-Best-Practices.md\n\u2502   \u2514\u2500\u2500 index.md               # Main index for MkDocs\n\u251c\u2500\u2500 notebooks/                 # (Currently empty, could be used for Jupyter notebooks)\n\u251c\u2500\u2500 src/                       # Source code for the application\n\u2502   \u251c\u2500\u2500 __init__.py            # Initialises the src package\n\u2502   \u251c\u2500\u2500 app.py                 # Main application file (GUI implementation)\n\u2502   \u251c\u2500\u2500 calculations.py        # Functions for time lag calculations\n\u2502   \u251c\u2500\u2500 data_processing.py     # Functions for loading and preprocessing data\n\u2502   \u251c\u2500\u2500 time_lag_analysis.py   # Workflow for performing time lag analysis\n\u2502   \u251c\u2500\u2500 util.py                # Utility functions and plot styling\n\u2502   \u2514\u2500\u2500 visualisation.py       # Functions for creating plots\n\u251c\u2500\u2500 tests/                     # (Planned, to house test scripts)\n\u251c\u2500\u2500 environment.yml            # Conda environment specification\n\u251c\u2500\u2500 LICENSE.md                 # Project license\n\u251c\u2500\u2500 mkdocs.yml                 # Configuration for MkDocs\n\u251c\u2500\u2500 README.md                  # This file\n\u251c\u2500\u2500 requirements-dev.txt       # Development dependencies (e.g., for MkDocs)\n\u2514\u2500\u2500 requirements.txt           # Core Python package dependencies\n</code></pre> <p>Code is organised into logical components:</p> <ul> <li><code>data</code>: Contains example experimental data files.</li> <li><code>docs</code>: Houses all user documentation, guides, and supporting images.</li> <li><code>src</code>: Contains the core Python scripts for the application's logic, calculations, data processing, and GUI.</li> <li><code>notebooks</code>: Reserved for potential Jupyter Notebooks for interactive exploration or tutorials.</li> <li><code>tests</code>: Reserved for future test scripts.</li> </ul>"},{"location":"#best-practice-notes","title":"Best Practice Notes \ud83d\udcdd","text":"<ul> <li>Reproducible environments: The <code>environment.yml</code> file ensures that users can create an identical Conda environment with all necessary dependencies.</li> <li>Modular code: The source code in <code>src/</code> is organised into modules with specific responsibilities (e.g., <code>data_processing.py</code>, <code>calculations.py</code>, <code>visualisation.py</code>, <code>app.py</code>).</li> <li>Documentation: Comprehensive documentation is provided in the <code>docs/</code> folder, built with MkDocs.</li> <li>Code comments: The Python scripts include comments to explain the logic.</li> <li>User-friendly GUI: The application features a GUI to make the analysis accessible to users without extensive programming knowledge.</li> <li>Future:<ul> <li>Code testing: Implementing unit and integration tests in the <code>tests/</code> directory.</li> <li>Continuous Integration (CI): Setting up CI pipelines for automated testing.</li> </ul> </li> </ul>"},{"location":"#additional-resources","title":"Additional Resources \ud83d\udd17","text":"<ul> <li>The <code>docs/</code> folder within this repository contains detailed guides and explanations.</li> <li>For specific Python libraries, refer to their official documentation:<ul> <li>NumPy</li> <li>Pandas</li> <li>SciPy</li> <li>Matplotlib</li> <li>CustomTkinter (built on Tkinter).</li> </ul> </li> </ul>"},{"location":"#license","title":"License \ud83d\udcc4","text":"<p>This project is licensed under the BSD-3-Clause license.</p>"},{"location":"01-Home/","title":"ReCode: Time Lag Analysis Application","text":""},{"location":"01-Home/#purpose-of-this-exemplar","title":"Purpose of this Exemplar","text":"<p>This exemplar serves as a learning tool for understanding how to design and structure scientific software. It is not intended to teach Python programming from scratch, but rather to demonstrate software design practices in a research context.</p> <p>The application in this exemplar analyses gas permeation through membrane materials using the time-lag method. While this method is primarily employed within diffusion modelling contexts in chemical engineering and materials science, it illustrates a framework for constructing a comprehensive computational workflow suitable for implementing diverse empirical methodologies in Python.</p> <p>Through this specific application, you will learn the principles of scientific software design. By the end of this exemplar, you will be able to adapt the code in this exemplar to your own research applications.</p>"},{"location":"01-Home/#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Techniques for processing experimental data.</li> <li>Implementation of numerical methods (PDE solving) using <code>scipy.solve_ivp</code>.</li> <li>Approaches for data visualisation using <code>matplotlib</code>.</li> <li>Building user interfaces for scientific applications using <code>CustomTkinter</code>.</li> <li>Create an end-to-end analysis workflow: from data extraction and processing to visualisation and saving results.</li> </ul>"},{"location":"01-Home/#before-you-begin","title":"Before You Begin","text":"<p>This exemplar assumes you have:</p> <ul> <li>Basic Python programming knowledge.</li> <li>Familiarity with scientific computing concepts.</li> <li>Understanding of numerical methods fundamentals.</li> <li>Experience with plotting data.</li> </ul>"},{"location":"01-Home/#how-to-use-this-documentation","title":"How to Use This Documentation","text":"<ol> <li>Start by understanding the theoretical background (<code>02-Theoretical-Background</code>).</li> <li>Learn about data management and processing (<code>03-Data-Management-and-Processing</code>).</li> <li>Explore the time lag analysis implementation (<code>04-TimelagAnalysis-Implementation</code>).</li> <li>Study the PDE solving approach with Python (<code>05-Python-PDE-Implementation</code>).</li> <li>Review scientific visualisation techniques (<code>06-Scientific-Visualisation</code>).</li> <li>Examine GUI implementation with <code>CustomTkinter</code> (<code>07-GUI-Implementation</code>).</li> <li>Understand how components integrate into a workflow (<code>08-Application-Workflow</code>).</li> <li>Test your understanding with exercises and learn best practices (<code>09-Exercises-and-Best-Practices</code>).</li> </ol>"},{"location":"01-Home/#major-steps-in-this-time-lag-analysis-app","title":"Major Steps in this Time Lag Analysis App","text":"<p>The implementation follows these key steps:</p> <ol> <li>Data Loading and Preprocessing - Loading experimental data files and preparing data for analysis.</li> <li>Stabilisation Time Detection - Identifying when the system reaches steady-state permeation.</li> <li>Linear Regression of Steady-State Data - Fitting the steady-state portion of the flux curve.</li> <li>Time Lag Calculation - Determining the time lag from the linear regression.</li> <li>Diffusion Coefficient Determination - Calculating diffusion coefficient from time lag.</li> <li>Permeability and Solubility Calculation - Computing additional transport parameters.</li> <li>PDE-Based Validation - Numerically solving the diffusion equation to validate results.</li> <li>Visualisation - Creating plots and visual representations of the analysis.</li> <li>Workflow Integration - Combining all steps into a cohesive analysis pipeline.</li> <li>GUI Implementation - Building a user-friendly interface to the analysis tools.</li> </ol>"},{"location":"01-Home/#navigation-guide","title":"Navigation Guide","text":""},{"location":"01-Home/#getting-started","title":"Getting Started","text":"<ul> <li><code>01-Home</code> - Introduction to the project and navigation guide.</li> <li><code>02-Theoretical-Background</code> - Scientific foundations and principles.</li> </ul>"},{"location":"01-Home/#core-implementation","title":"Core Implementation","text":"<ul> <li><code>03-Data-Management-and-Processing</code> - Data handling and processing (Step 1).</li> <li><code>04-TimelagAnalysis-Implementation</code> - Core analysis algorithms (Steps 2-6).</li> <li><code>05-Python-PDE-Implementation</code> - PDE-based validation (Step 7).</li> </ul>"},{"location":"01-Home/#user-interface-and-visualisation","title":"User Interface and Visualisation","text":"<ul> <li><code>06-Visualisation</code> - Creating effective visualisations (Step 8).</li> <li><code>07-GUI-Implementation</code> - Building interfaces with CustomTkinter (Step 10).</li> </ul>"},{"location":"01-Home/#integration-and-practice","title":"Integration and Practice","text":"<ul> <li><code>08-Application-Workflow</code> - Combining components cohesively (Step 9).</li> <li><code>09-Exercises-and-Best-Practices</code> - Hands-on activities and best practices.</li> </ul>"},{"location":"02-Theoretical-Background/","title":"Time Lag Analysis: A Theoretical Foundation","text":""},{"location":"02-Theoretical-Background/#tldr","title":"TLDR","text":"<p>The time lag method determines a material's diffusion coefficient  and solubility coefficient  from a single gas permeation experiment. Plotting cumulative permeated flux versus time reveals a linear steady-state region. Extrapolating this line to the time axis yields the 'time lag' , allowing calculation of the diffusion coefficient: , where  is membrane thickness. The slope of the steady-state line relates directly to the permeability , and since , the solubility coefficient is found via . This technique, pioneered by Daynes (1920) and Barrer (1939), is fundamental for characterising gas transport in membranes.</p>"},{"location":"02-Theoretical-Background/#introduction-to-gas-transport-phenomena","title":"Introduction to Gas Transport Phenomena","text":"<p>Gas transport through membranes is a fundamental process in many areas of chemical engineering, materials science, and environmental applications. Understanding and quantifying this transport is essential for designing materials for gas separation, barrier materials, and controlled release systems. The gas-polymer system uses throughout this exemplar is carbon dioxide (CO) in High-Density Polyethylene (HDPE).</p>"},{"location":"02-Theoretical-Background/#the-permeation-experiment","title":"The Permeation Experiment","text":"<p>A typical gas permeation experiment involves placing a membrane sample between two chambers. One chamber (upstream) is pressurized with the gas of interest, while the other chamber (downstream) is kept at a low pressure, often by using a sweep gas. The amount of gas that permeates through the membrane to the downstream side is then measured over time.</p> <p>The key steps of the experiment include:</p> <ol> <li>A gas is introduced on one side of a membrane at time . The downstream pressure is maintained by using a continuously sweeping flow of nitrogen (N). This ensures the concentration at the downstream face of the membrane remains effectively zero.</li> <li>The gas flux through the membrane is measured over time on the permeate side.</li> <li>Initially, there is a transient state as the concentration profile develops in the membrane.</li> <li>Eventually, a steady-state is reached with a constant flux.</li> </ol> <p>These key steps are illustrated in Figure 1. </p> <p></p> <p>Figure 1: Schematic representation of the permeation of CO through a polymer membrane.</p> <p>The time lag method enables a single value of diffusion coefficient to be calculated based on the measured flux. This is because the transition from the initial transient state (step 3) to steady-state flux (step 4) becomes apparent when plotting the cumulative permeated gas versus time. Extrapolating the linear steady-state portion of this curve yields the time lag, the basis for calculating the diffusion coefficient, as explained in the sections below.</p>"},{"location":"02-Theoretical-Background/#the-time-lag-method","title":"The Time Lag Method","text":"<p>The time-lag method was first developed and applied to gas diffusion studies in the early 20th century by Daynes [1] and further developed by Barrer [2].</p> <p>These works established the theoretical foundation that remains the basis for contemporary membrane permeation analysis.</p> <p>The time-lag method is a technique used to determine two key transport parameters simultaneously:</p> <ul> <li>Diffusion coefficient  </li> <li>Solubility coefficient  </li> </ul> <p>Together, these parameters determine the material's permeability:</p> <p> </p>"},{"location":"02-Theoretical-Background/#theoretical-background","title":"Theoretical Background","text":""},{"location":"02-Theoretical-Background/#ficks-laws-and-boundary-conditions","title":"Fick's Laws and Boundary Conditions","text":"<p>The time-lag method is based on Fick's laws of diffusion:</p> <ol> <li>Fick's First Law: </li> </ol> <p>This relates the diffusive flux to the concentration gradient.</p> <p> </p> <p>where:</p> <ul> <li>  is the diffusion flux </li> <li>  is the diffusion coefficient </li> <li>  is the concentration </li> <li> <p>  is position </p> </li> <li> <p>Fick's Second Law: </p> </li> </ul> <p>This describes how concentration changes with time due to diffusion.</p> <p> </p> <ol> <li>Boundary Conditions:</li> </ol> <p>For a membrane of thickness :</p> <ul> <li>  (upstream side concentration)</li> <li>  (downstream side concentration, assumed to be perfectly evacuated)</li> <li>  (initial condition: no gas in membrane)</li> </ul> <p>Figures 2 and 3 below visualise the solution to Fick's Second Law for the specified boundary conditions, obtained using the numerical methods described in <code>05-Python-PDE-Implementation</code>. Figure 2 presents the concentration evolution  as a heatmap, while Figure 3 shows concentration profiles  at discrete time points. These specific plots correspond to the parameters derived from the <code>RUN_H_25C-100bar_9.csv</code> dataset.</p> <p></p> <p>Figure 2: Concentration profile evolution over time.</p> <p></p> <p>Figure 3: Concentration profiles at specific time points.</p> <p>Observing the figures provides insights into the diffusion process governed by Fick's laws and the specified conditions:</p> <ul> <li>Fixed ends (boundary conditions):</li> <li>Figure 2: The bright red color along the left edge () shows the constant high gas concentration  maintained on the upstream side. The dark blue color along the right edge () shows the near-zero concentration maintained on the downstream side.</li> <li> <p>Figure 3: Every concentration line starts at the high value  on the left () and drops to zero on the right (). This confirms the fixed concentrations at the membrane boundaries throughout the experiment.</p> </li> <li> <p>Empty start  (initial condition):</p> </li> <li>Figure 2: The bottom edge of the heatmap (representing ) is blue across the membrane width (for ), indicating that initially, there was no gas dissolved in the membrane.</li> <li> <p>Figure 3: The \"t=0\" line is flat at zero concentration (except for the upstream boundary at ), showing the initial empty state of the membrane.</p> </li> <li> <p>Gas spreading over time (transient diffusion):</p> </li> <li>Figure 2: As you move upwards (increasing time), the color gradient (from red to blue) moves across the membrane from left to right. This indicates the gas gradually diffusing through the material.</li> <li> <p>Figure 3: The lines for early times (such as t=75s and t=126s) are steeply curved, especially near the left side (). This shows that the concentration is changing rapidly as the gas first enters and spreads.</p> </li> <li> <p>Reaching a balance (steady state):</p> </li> <li>Figure 2: At later times (towards the top of the heatmap), the color pattern stops changing significantly with time. The gradient becomes stable.</li> <li>Figure 3: The concentration lines become less curved over time. The line for t=7530s is almost perfectly straight. A straight line profile indicates that the rate of gas entering and leaving any section of the membrane has become constant \u2013 this is the steady state.</li> </ul>"},{"location":"02-Theoretical-Background/#the-time-lag-derivation","title":"The Time Lag Derivation","text":"<p>Figure 4:  Graphical determination of the time lag  by extrapolating the linear steady-state region of the cumulative flux curve to the time axis [3].</p> <p>When gas permeation reaches steady state, the cumulative amount of gas that has permeated through the membrane  follows:</p> <p> </p> <p>The time-lag  is determined graphically by extrapolating the linear steady-state portion of the cumulative flux curve to the time axis (x-intercept), as illustrated in Figure 4. This time lag is related to the diffusion coefficient  and membrane thickness  by the equation:</p> <p> </p> <p>Therefore:</p> <p> </p> <p>The permeability  is related to the steady-state flux  and pressure difference  :</p> <p> </p> <p>The solubility coefficient  can be calculated from  and  based on the definition for  :</p> <p> </p> <p>Upstream solubility  can be calculated:</p> <p> </p>"},{"location":"02-Theoretical-Background/#units-and-conventions","title":"Units and Conventions","text":"<p>In this application, we use the following units:</p> <ul> <li>Length: centimeters [cm]</li> <li>Time: seconds [s]</li> <li>Pressure: bar [bar]</li> <li>Amount of substance: standard cubic centimeters at \"Standard Temperature and Pressure\" [cm\u00b3(STP)]. This unit, representing the volume a quantity of gas would occupy at STP (0\u00b0C, 1 atm), functions as a measure of amount (like moles). Although an older convention, it remains prevalent in membrane science and engineering, and is therefore used throughout this exemplar.</li> </ul> <p>The key parameters have these units:</p> <ul> <li>Time lag : [s]</li> <li>Diffusion coefficient : [cm\u00b2/s]</li> <li>Permeability : [cm\u00b3(STP)\u00b7cm/(cm\u00b2\u00b7s\u00b7bar)]</li> <li>Solubility coefficient : [cm\u00b3(STP)/(cm\u00b3\u00b7bar)]</li> <li>Solubility : [cm\u00b3(STP)/cm\u00b3]</li> </ul>"},{"location":"02-Theoretical-Background/#significance-and-applications","title":"Significance and Applications","text":"<p>The time lag method provides:</p> <ul> <li>A straightforward way to determine both diffusion and solubility coefficients</li> <li>Insights into the transport mechanisms through polymers and other materials</li> <li>Data essential for designing gas separation membranes, food packaging, and barrier materials</li> </ul> <p>In this application, we implement the time lag method for analysing experimental permeation data and visualising the results, providing a computational tool that researchers can use and adapt to their specific needs.</p>"},{"location":"02-Theoretical-Background/#limitations-of-the-time-lag-method","title":"Limitations of the Time Lag Method","text":"<p>While the time lag method is a powerful technique, it has several important limitations that should be considered:</p> <ol> <li>Constant diffusion coefficient assumption: The classical time lag method assumes that the diffusion coefficient is concentration-independent. For materials with strong gas-polymer interactions, this assumption may not hold, leading to inaccurate results.</li> <li>Steady-state requirement: Accurate time lag determination requires reaching true steady-state conditions. Premature termination of experiments can lead to incorrect extrapolation and inaccurate diffusion coefficients.</li> <li>Downstream boundary condition: The method requires maintaining near-zero concentration at the downstream membrane face. Insufficient sweep gas flow or downstream accumulation can violate this condition, compromising time lag accuracy.</li> </ol> <p>These limitations highlight the importance of careful experimental design and thoughtful interpretation of results when using the time lag method for membrane characterisation.</p>"},{"location":"02-Theoretical-Background/#bibliography","title":"Bibliography","text":"<p>[1] Daynes, H.A. \"The process of diffusion through a rubber membrane.\" Royal Society Proceedings, 97 (1920), pp. 286-307.</p> <p>[2] Barrer, R.M. \"Permeation, diffusion and solution of gases in organic polymers.\" Transactions of the Faraday Society, 35 (1939), pp. 628-643.</p> <p>[3] Paul, D.R. \"Time Lag Method for Mass Transport Properties Evaluation in GS.\" In: Drioli, E., Giorno, L. (eds) Encyclopedia of Membranes. Springer, Berlin, Heidelberg (2016).</p>"},{"location":"03-Data-Management-and-Processing/","title":"Data Management and Processing","text":""},{"location":"03-Data-Management-and-Processing/#data-management-in-research","title":"Data Management in Research","text":""},{"location":"03-Data-Management-and-Processing/#best-practices-for-experimental-data-management","title":"Best Practices for Experimental Data Management","text":"<p>Good data management is essential for reproducible research. When working with experimental data, consider these practices:</p> <ol> <li>Consistent file naming: Use descriptive, consistent naming schemes (e.g., <code>RUN_H_25C-100bar_7.xlsx</code> clearly indicates temperature and pressure conditions).</li> <li>Data organisation: Organise data in a logical folder structure with clear separation between raw data and processed outputs.</li> <li>Metadata recording: Document experimental conditions, sample details, and measurement parameters.</li> <li>Version control: Track changes to your data processing scripts using version control systems such as Git.</li> <li>Data backup: Regularly back up your research data to prevent loss. Utilise cloud storage services (like OneDrive) when possible.</li> </ol>"},{"location":"03-Data-Management-and-Processing/#data-structure-for-time-lag-analysis","title":"Data Structure for Time-Lag Analysis","text":"<p>For permeation experiments specifically, data should include:</p> <ul> <li>Time measurements (seconds)</li> <li>Pressure readings (bar or barg)</li> <li>Temperature readings (\u00b0C)</li> <li>Gas concentration measurements (ppm)</li> <li>Flow rates (ml/min)</li> <li>Sample dimensions (thickness, diameter)</li> </ul>"},{"location":"03-Data-Management-and-Processing/#data-processing-workflow","title":"Data Processing Workflow","text":"<p>The application implements a data processing pipeline in <code>data_processing.py</code> consisting of several key steps:</p>"},{"location":"03-Data-Management-and-Processing/#1-loading-data","title":"1. Loading Data","text":"<p>Raw experimental data is loaded from Excel files using the <code>load_data</code> function.</p>"},{"location":"03-Data-Management-and-Processing/#2-data-preprocessing","title":"2. Data Preprocessing","text":"<p>The <code>preprocess_data</code> function performs several preprocessing steps:</p> <ol> <li> <p>Baseline correction: Remove background signals from gas concentration measurements. <pre><code>df['y_CO2_bl / ppm'] = df['y_CO2 / ppm'] - baseline\n</code></pre></p> </li> <li> <p>Pressure conversion: Convert pressure readings to standard units (bar). <pre><code>df['P_cell / bar'] = df['P_cell / barg'] + 1.01325\n</code></pre></p> </li> <li> <p>Flux calculation: Calculate gas flux through the membrane from provided polymer disc thickness (<code>d_cm</code>) and N\u2082 sweeping gas flowrate (<code>qN2_mlmin</code>). <pre><code># Calculate Area of disc\nA_cm2 = (math.pi * d_cm**2) / 4 # [cm^2]\n\n# Specify mass flow rate of N2 in [ml/min]\nif qN2_mlmin is not None:\n    df['qN2 / ml min^-1'] = qN2_mlmin\nelif 'qN2 / ml min^-1' not in df.columns:\n    raise ValueError(\"Column 'qN2 / ml min^-1' does not exist in the DataFrame.\")\n\n# Calculate flux\nif unit == 'cm^3 cm^-2 s^-1' or unit == 'None':\n    df['flux / cm^3(STP) cm^-2 s^-1'] = (df['qN2 / ml min^-1'] / 60) * (df['y_CO2_bl / ppm'] * 1e-6) / A_cm2\n</code></pre></p> </li> <li> <p>Cumulative flux calculation: Integrate experimental flux over time to obtain cumulative flux. <pre><code>df['cumulative flux / cm^3(STP) cm^-2'] = (df['flux / cm^3(STP) cm^-2 s^-1'] * df['t / s'].diff().fillna(0)).cumsum()\n</code></pre></p> </li> </ol>"},{"location":"03-Data-Management-and-Processing/#3-stabilisation-time-detection","title":"3. Stabilisation Time Detection","text":"<p>An important aspect of time-lag analysis is determining when steady-state diffusion has been reached. This is performed in <code>identify_stabilisation_time</code> function.</p> <p>The following steps are performed:</p> <ol> <li> <p>Calculates the gradient of the specified data column. <pre><code>df['gradient'] = (df[column].diff() / df['t / s'].diff())\n</code></pre></p> </li> <li> <p>Examines changes in this gradient over a rolling window. <pre><code>df['pct_change_mean'] = (df[column].diff() / df['t / s'].diff()).pct_change().abs().rolling(window=window).mean()\ndf['pct_change_min'] = (df[column].diff() / df['t / s'].diff()).pct_change().abs().rolling(window=window).min()\ndf['pct_change_max'] = (df[column].diff() / df['t / s'].diff()).pct_change().abs().rolling(window=window).max()\ndf['pct_change_median'] = (df[column].diff() / df['t / s'].diff()).pct_change().abs().rolling(window=window).median()\n</code></pre></p> </li> <li> <p>Identifies when changes fall below a specified threshold. <pre><code>stabilisation_index = df[((df['pct_change_mean'] &lt;= threshold))].index[0]\nstabilisation_time = df.loc[stabilisation_index, 't / s']\n</code></pre></p> </li> </ol>"},{"location":"03-Data-Management-and-Processing/#input-output-and-configuration","title":"Input, Output, and Configuration","text":""},{"location":"03-Data-Management-and-Processing/#data-input","title":"Data Input","text":"<p>The application expects data files in the <code>data/</code> directory with experimental data organised in Excel files. Sample data files are available in this location for reference.</p> <pre><code>data/\n    RUN_H_25C-100bar_7.xlsx\n    RUN_H_25C-100bar_8.xlsx\n    RUN_H_25C-100bar_9.xlsx\n    RUN_H_25C-200bar_2.xlsx\n    RUN_H_25C-50bar.xlsx\n    ...\n</code></pre> <p>When using the application, ensure your data files adhere to the following specifications:</p> <ol> <li> <p>Required columns: Each file must contain, at minimum, the following data columns with the specified headers:</p> <ul> <li><code>t / s</code>: Time, measured in seconds.</li> <li><code>P_cell / barg</code>: Cell pressure, measured in bar gauge.</li> <li><code>T / \u00b0C</code>: Temperature, measured in degrees Celsius.</li> <li><code>y_CO2 / ppm</code>: Carbon dioxide concentration, measured in parts per million.</li> </ul> </li> <li> <p>Unit consistency: Ensure that units are consistent across all measurements within and between files intended for comparative analysis.</p> </li> <li> <p>File format: Data must be provided in either Excel (<code>.xlsx</code>, <code>.xls</code>) or CSV (<code>.csv</code>) format.</p> </li> </ol>"},{"location":"03-Data-Management-and-Processing/#output-data","title":"Output Data","text":"<p>Following the pre-processing steps in <code>preprocess_data.py</code>, the main analysis is performed in <code>calculation.py</code> (explained in depth in <code>04-TimelagAnalysis-Implementation</code>). These steps are encompassed in the complete workflow function <code>time_lag_analysis_workflow</code> in <code>time_lag_analysis.py</code>. The workflow will be explained in depth in <code>08-Application-Workflow</code>. This workflow can generate several output files:</p> <ol> <li>Preprocessed data: Contains the cleaned and transformed experimental data.</li> <li>Time lag analysis results: Contains the calculated parameters (diffusion coefficient, permeability, etc.).</li> <li>Concentration profiles: Shows how gas concentration changes with position and time.</li> <li>Flux profiles: Shows the calculated gas flux over time.</li> </ol>"},{"location":"03-Data-Management-and-Processing/#experimental-metadata-configuration","title":"Experimental Metadata Configuration","text":"<p>The <code>util.py</code> file contains configuration dictionaries for experimental parameters:</p> <pre><code>thickness_dict = {\n    'RUN_H_25C-50bar': 0.1, 'RUN_H_25C-100bar_7': 0.1, \n    # ... other thickness values\n} # [cm]\n\nqN2_dict = {\n    'RUN_H_25C-50bar': 8.0, 'RUN_H_25C-100bar_7': 8.0,\n    # ... other flow rate values\n}  # [ml min^-1]\n</code></pre> <p>The dictionaries provide essential metadata for each experiment:</p> <ul> <li><code>thickness_dict</code>: Membrane thickness in cm</li> <li><code>qN2_dict</code>: Nitrogen flow rate in ml/min</li> </ul> <p>This separation centralises the metadata in <code>util.py</code>, enhancing maintainability. It ensures consistency and simplifies updates across the analysis. For example, when calculating permeability for <code>'RUN_H_25C-100bar_7'</code>, the code retrieves the thickness <code>0.1</code> directly from <code>thickness_dict</code>. If this value needed correction, it would only require changing it once in <code>util.py</code>.</p>"},{"location":"03-Data-Management-and-Processing/#data-flow-diagram","title":"Data Flow Diagram","text":"<pre><code>flowchart TD\n    A[\"Raw Data Files (.xlsx, .csv)\"] --&gt; B[\"Data Loading: &lt;br&gt;load_data()\"]\n    B --&gt; C[\"Data Preprocessing: &lt;br&gt;preprocess_data()\"]\n    D[\"Membrane Data:&lt;br&gt;thickness_dict &lt;br&gt;qN2_dict\"] --&gt; E[\"Data Transformation:&lt;br&gt;- Baseline correction &lt;br&gt;- Unit conversion &lt;br&gt;- Flux calculation\"]\n    C --&gt; E\n    E --&gt; F[\"Stabilisation Detection:&lt;br&gt;identify_stabilisation_time()\"]\n    F --&gt; G[\"Time-Lag Analysis:&lt;br&gt;time_lag_analysis_workflow()\"]\n    G --&gt; H[\"Preprocessed Data (.csv)\"]\n    G --&gt; I[\"Analysis Results (.csv)\"]\n    G --&gt; J[\"Profile Data (.csv)\"]</code></pre>"},{"location":"03-Data-Management-and-Processing/#extending-the-data-processing-pipeline","title":"Extending the Data Processing Pipeline","text":"<p>To implement your own data processing steps:</p> <ol> <li>Add new functions to <code>data_processing.py</code>.</li> <li>Integrate them into the <code>preprocess_data</code> function.</li> <li>Update the <code>time_lag_analysis_workflow</code> function to use your new processing steps.</li> </ol>"},{"location":"04-TimelagAnalysis-Implementation/","title":"Time Lag Analysis Core Calculation Implementation","text":"<p>This document details the <code>time_lag_analysis</code> function within <code>calculations.py</code>, which implements the core calculations for time lag analysis. This function converts experimental permeation data into gas transport parameters.</p>"},{"location":"04-TimelagAnalysis-Implementation/#core-calculation-steps","title":"Core Calculation Steps","text":"<p>The <code>time_lag_analysis</code> function implements four key computational steps:</p> <ol> <li>Linear Regression of Steady-State Data</li> <li>Time Lag Calculation</li> <li>Diffusion Coefficient Determination</li> <li>Permeability and Solubility Calculation</li> </ol> <p>These steps form the analytical core of the time lag method (covered in <code>02-Theoretical-Background</code>), following data preprocessing and stabilisation time detection (covered in <code>03-Data-Management-and-Processing</code>).</p>"},{"location":"04-TimelagAnalysis-Implementation/#implementation-in-the-time_lag_analysis-function","title":"Implementation in the <code>time_lag_analysis</code> Function","text":""},{"location":"04-TimelagAnalysis-Implementation/#1-linear-regression-of-steady-state-data","title":"1. Linear Regression of Steady-State Data","text":"<p>First, the steady-state region of flux is filtered. This corresponds to a linear change of cumulative flux against time as seen in the plot in <code>02-Theoretical-Background</code>.</p> <pre><code># Filter to steady-state data\ndf_ss = df[df['t / s'] &gt; stabilisation_time_s]\n</code></pre> <p>Next, the core calculation uses NumPy's <code>polyfit</code> function to perform linear regression on the filtered  portion of the cumulative flux curve.</p> <pre><code># Fitting straight line to the steady-state data\nslope, intercept = np.polyfit(df_ss['t / s'], df_ss['cumulative flux / cm^3(STP) cm^-2'], 1)\n</code></pre> <p>This fits the data to the linear equation , where:</p> <ul> <li>  is the cumulative flux (<code>cumulative flux / cm^3(STP) cm^-2</code>)</li> <li>  is the time (<code>t / s</code>)</li> <li>  is the <code>slope</code> variable</li> <li>  is the <code>intercept</code> variable</li> </ul> <p>The variables returned from <code>polyfit</code> have important physical meaning:</p> <ul> <li><code>slope</code>: Represents the steady-state flux through the membrane.</li> <li><code>intercept</code>: Represents the y-intercept of the extrapolated steady-state line. This is important for calculating the time lag.</li> </ul>"},{"location":"04-TimelagAnalysis-Implementation/#2-time-lag-calculation","title":"2. Time Lag Calculation","text":"<p>The time lag  is calculated by finding the x-intercept of the steady-state line by setting :</p> <p> </p> <p>Rearranging for  gives:</p> <p> </p> <pre><code># Calculate time lag\ntime_lag = -intercept / slope   # [s]\n</code></pre>"},{"location":"04-TimelagAnalysis-Implementation/#3-diffusion-coefficient-determination","title":"3. Diffusion Coefficient Determination","text":"<p>The diffusion coefficient  is calculated using the formula introduced in <code>02-Theoretical-Background</code>:</p> <p> </p> <pre><code># Calculate diffusion coefficient\ndiffusion_coefficient = thickness**2 / (6 * time_lag)   # [cm^2 s^-1]\n</code></pre>"},{"location":"04-TimelagAnalysis-Implementation/#4-permeability-and-solubility-calculation","title":"4. Permeability and Solubility Calculation","text":"<p>The derived formulae in  <code>02-Theoretical-Background</code> is used to calculate permeability , solubility coefficient  and solubility .</p> <p>Permeability is calculed with:  </p> <p>where  is the steady-state flux and  is the pressure.</p> <pre><code># Calculate permeability\npermeability = thickness * slope / pressure   # [cm^3(STP) cm cm^-2 s^-1 bar^-1]\n</code></pre> <p>The solubility coefficient is calculted with:  </p> <pre><code># Calculate solubility coefficient\nsolubility_coefficient = permeability / diffusion_coefficient   # [cm^3(STP) cm^-3 bar^-1]\n\n# Calculate solubility (concentration)\nsolubility = solubility_coefficient * pressure\n</code></pre> <p>Finally, the solubility can be calculated from:  </p> <pre><code># Calculate solubility (concentration)\nsolubility = solubility_coefficient * pressure\n</code></pre>"},{"location":"05-Python-PDE-Implementation/","title":"PDE Solver Implementation for Gas Diffusion","text":""},{"location":"05-Python-PDE-Implementation/#overview","title":"Overview","text":"<p>This document details the implementation of <code>solve_constant_diffusivity_model</code> in <code>calculations.py</code>, which numerically solves the gas diffusion equation for polymer membranes under specific boundary conditions. The implementation uses the Method of Lines approach with SciPy's <code>solve_ivp</code> function to solve Fick's Second Law of Diffusion. For the governing equations (Fick's Second Law) and boundary conditions, please refer to the explanation and visualisations in <code>02-Theoretical-Background</code>.</p>"},{"location":"05-Python-PDE-Implementation/#implementation-structure","title":"Implementation Structure","text":"<p>The <code>solve_constant_diffusivity_model</code> function is implemented through a series of helper functions.</p> <p>The implementation is divided into five main sections:</p> <ol> <li>PDE Solution</li> <li>Flux Calculation</li> <li>Post-processing</li> </ol>"},{"location":"05-Python-PDE-Implementation/#1-pde-solution","title":"1. PDE Solution","text":"<p>The PDE solving logic is encapsulated inside the <code>_solve_diffusion_pde</code> helper function. This includes three main stages:</p> <ol> <li> <p>Setup</p> <p>The discretisation setup is performed using <code>_setup_grid</code> helper function. <pre><code>x_grid, t_grid, Nx, Nt = _setup_grid(L, T, dx, dt)\n</code></pre></p> <p>The <code>_setup_grid</code> function performs the following:</p> <ul> <li> <p>Calculates the number of spatial grid points (<code>Nx</code>) and output time points (<code>Nt</code>) based on the domain dimensions and step sizes.     <pre><code># Calculate number of points\nNx = round(L / dx) + 1\nNt = round(T / dt) + 1\n</code></pre></p> </li> <li> <p>Creates discretisation for both space and time domains.     <pre><code># Create grids\nx_grid = np.linspace(0, L, Nx)\nt_grid = np.linspace(0, T, Nt)    \n</code></pre></p> </li> </ul> </li> <li> <p>ODE System Definition</p> <p>The PDE initial conditions are created using <code>_create_initial_condition</code> helper functions to achieve the following:     <pre><code># Create initial condition\ninitial_condition = _create_initial_condition(Nx, C_eq)\n</code></pre></p> <p>The <code>_create_initial_condition</code> function performs the following:</p> <ul> <li> <p>Creates a concentration profile where C(x,0) = 0 everywhere.     <pre><code>C_init = np.zeros(Nx)\n</code></pre></p> </li> <li> <p>An exception of the initial condition above is at the feed side (x=0) where C(0,0) = C_eq.     <pre><code>C_init[0] = C_eq  # Apply boundary condition at x=0 (feed side)\n</code></pre></p> </li> </ul> </li> <li> <p>PDE Solution</p> <p>The Method of Lines is a technique for solving PDEs by:</p> <ol> <li>Discretising the spatial derivatives to convert the PDE into a system of ODEs.</li> <li>Solving the resulting ODE system using standard ODE solvers.</li> </ol> <p>The PDE is solved using SciPy's <code>solve_ivp</code> function with the Method of Lines approach.</p> <pre><code>sol = solve_ivp(\n    _diffusion_ode,\n    (0, T),\n    initial_condition,\n    method='BDF',\n    t_eval=t_grid,\n    args=(diffusion_coeff, dx),\n    rtol=1e-4,\n    atol=1e-6\n)\n</code></pre> <p>The arguments passed to <code>solve_ivp</code> are:</p> <ul> <li><code>_diffusion_ode</code>: Corresponds to the <code>_diffusion_ode</code> function that defines the system of Ordinary Differential Equations (ODEs) for <code>solve_ivp</code> by calculating the concentration's rate of change (dC/dt) at each spatial point based on the Method of Lines (using discretised PDE). The rate change provided by <code>_diffusion_ode</code> is used to step forward in time and determine the concentration profile.</li> <li><code>(0, T)</code>: Specifies the time interval over which the ODE system should be solved (starts at time t=0 and ends at time t=T).</li> <li><code>initial_condition</code>: Corresponds to the previously calculated variable that represents the state of the system (i.e., concentration at each spatial grid point) at the beginning of the time interval (t=0).</li> <li><code>method='BDF'</code>: Uses the Backward Differentiation Formula (BDF), which is suitable for solving stiff ODE systems.</li> <li><code>t_eval=t_grid</code>: Specifies time points (<code>t_grid</code>) at which the solver should store and return the solution. Without this, the solver might choose its own internal time steps.</li> <li><code>args=(diffusion_coeff, dx)</code>: Passes additional arguments required by the <code>_diffusion_ode</code> function beyond the <code>t</code> (time) and <code>y</code> (concentration). In this case, it passes the <code>diffusion_coeff</code> (diffusion coefficient) and <code>dx</code> (spatial step size) needed to calculate the concentration derivatives.</li> <li><code>rtol=1e-4</code> and <code>atol=1e-6</code>: Specifies the relative tolerance (<code>rtol</code>) and absolute tolerance (<code>atol</code>) to control integration accuracy. Setting these values too high can lead to inaccurate results, while setting these values too low increases computation time.</li> </ul> </li> </ol>"},{"location":"05-Python-PDE-Implementation/#2-flux-calculation","title":"2. Flux Calculation","text":"<p>The gas flux at the downstream face (x=L) using Fick's First Law is calculated using <code>_calculate_flux</code> helper function.</p> <pre><code># Calculate flux values\nflux_values = _calculate_flux(diffusion_coeff, C_surface, dx)\n</code></pre> <p>The <code>_calculate_flux</code> function approximates the concentration gradient  using backward difference: .</p> <pre><code># Calculate flux at x=L using Fick's first law: J = -D\u00b7(\u2202C/\u2202x)\nflux_values = -diffusion_coeff * (C_surface[:, -1] - C_surface[:, -2]) / dx\n</code></pre>"},{"location":"05-Python-PDE-Implementation/#3-post-processing","title":"3. Post-processing","text":"<p>After the PDE solution is obtained amd the flux profile is calculated, the following is performed:</p> <ol> <li> <p>Creates a concentration profile DataFrame with position columns and time as a row index.     <pre><code># Transpose the solution array to get more common dimensions (time, position) instead of (position, time)\n# for easier visualisation and data processing in downstream functions\nC_surface = _prepare_concentration_profile(sol)\n</code></pre></p> </li> <li> <p>Converts the numerical results into pandas DataFrames for easier data manipulation and analysis.     <pre><code># Calculate flux values\nflux_values = _calculate_flux(diffusion_coeff, C_surface, dx)\n</code></pre></p> </li> </ol>"},{"location":"05-Python-PDE-Implementation/#benefits-of-this-approach","title":"Benefits of This Approach","text":"<p>Using <code>solve_ivp</code> offers the many benefits, including:</p> <ol> <li>Accuracy: Uses advanced ODE solvers with adaptive time stepping.</li> <li>Stability: BDF method is well-suited for stiff diffusion problems.</li> <li>Efficiency: Method of Lines is computationally efficient for 1D problems.</li> <li>Speed: Utilises a pre-built, tested solver, reduces development time and potential errors compared to implementing a custom solver.</li> </ol> <p>The concentration profile and flux calculated in this implementation enable a direct comparison with experimental flux (detailed in  <code>06-Visualisation</code>). This comparison validates the diffusion coefficient used in the model. Within the full application workflow (detailed in <code>08-Application-Workflow</code>), this validation step helps to verify the diffusion coefficient derived from the graphical time lag analysis.</p>"},{"location":"06-Visualisation/","title":"Scientific Visualisation Implementation","text":"<p>This document explains how the scientific visualisations are implemented in the application. </p>"},{"location":"06-Visualisation/#overview","title":"Overview","text":"<p>The <code>visualisation.py</code> file provides specialised plotting functions to help interpret time lag analysis results. The visualisations in this application are implemented using Matplotlib and includes functions for generating the plots and another function for managing their visual style.</p>"},{"location":"06-Visualisation/#core-visualisation-functions","title":"Core Visualisation Functions","text":""},{"location":"06-Visualisation/#1-time-lag-analysis-plot","title":"1. Time Lag Analysis Plot","text":"<p>The <code>plot_time_lag_analysis</code> function plots the cumulative flux (y-axis) against time (x-axis) which is used to calculate the time lag , as previously shown in <code>04-TimelagAnalysis-Implementation</code>. This plot is important for validating the time lag analysis.</p> <p>The core features are:</p> <ul> <li>Experimental data: The cumulative flux based on raw data is plotted as a function of time.</li> <li>Steady-state fit: A linear fit to the steady-state portion of the curve.</li> <li>Extrapolation: An extension of the steady-state line to earlier times. This provides visual determination for time lag .</li> </ul> <p></p> <p>Figure 1: Example time lag analysis plot (<code>RUN_H_25C-100bar_9</code> data) produced by the <code>plot_time_lag_analysis</code> function.</p>"},{"location":"06-Visualisation/#2-flux-profile-comparison-plot","title":"2. Flux Profile Comparison Plot","text":"<p>The <code>plot_flux_over_time</code> function plots flux (y-axis) against time (x-axis), comparing experimental data and theoretical predictions from the PDE solver. This demonstrates how well the model reproduces the data.</p> <p>The core features are:</p> <ul> <li>Theoretical curve: Displayed as a continuous line to represent the model prediction.</li> <li>Experimental data: Plotted as points to show the raw measurements.</li> </ul> <p></p> <p>Figure 2: Example of flux comparison plot (<code>RUN_H_25C-100bar_9</code> data) produced by the <code>plot_flux_over_time</code> function.</p>"},{"location":"06-Visualisation/#3-concentration-profile-snapshot-plot","title":"3. Concentration Profile Snapshot Plot","text":"<p>The <code>plot_concentration_location_profile</code> function plots multiple curves for the spatial distribution of gas concentration (y-axis) along the position within the membrane (x-axis), with each curve representing a specific snapshot in time. This helps with the intuitive understanding of the gas diffusion process within the membrane and validate that the PDE solver is correctly implementing the physical model.</p> <p>The core features are:</p> <ul> <li>Multiple time points: Multiple curves reprent different time snapshot of concentration-time profile during the diffusion process.</li> <li>Spatial dimension: Displays concentration as a function of position within the membrane.</li> </ul> <p></p> <p>Figure 3: Example of the concentration profile snapshot plot (<code>RUN_H_25C-100bar_9</code> data) produced by the <code>plot_concentration_location_profile</code> function.</p>"},{"location":"06-Visualisation/#4-concentration-profile-heatmap-plot","title":"4. Concentration Profile Heatmap Plot","text":"<p>In contrast, the <code>plot_concentration_profile</code> function creates a 2D heatmap that visualises the gas concentration (colour intensity) across both membrane position (x-axis) and continuous time (y-axis). This provides a comprehensive overview of evolution of the concentration profile throughout the membrane over the full duration, complementing the discrete snapshots provided by <code>plot_concentration_location_profile</code>.</p> <p>The core features are:</p> <ul> <li>Heatmap representation: Uses blue-to-red colour gradient to represent low-to-high gas concentration.</li> <li>Temporal and spatial dimensions: Displays the concentration evolution continuously over time and position within the membrane.</li> </ul> <p></p> <p>Figure 4: Example of the concentration profile hetmap plot (<code>RUN_H_25C-100bar_9</code> data) produced by the <code>plot_concentration_profile</code> function.</p>"},{"location":"06-Visualisation/#consistent-plot-styling","title":"Consistent Plot Styling","text":""},{"location":"06-Visualisation/#implementation","title":"Implementation","text":"<p>The <code>set_plot_style</code> function in <code>utils.py</code> file maintains consistency across all Matplotlib plots generated by the application. This function is called at the beginning of each plotting routine to apply the standard style. </p> <p>The styling is done through modifying Matplotlib's <code>rcParams</code>, which dictates the style for any subsequently created figures within the current session. A snippet of the <code>rcParams</code> modification is provided below.</p> <pre><code>    # Define consistent plot aesthetics\n    plt.rcParams['font.size'] = 10\n    plt.rcParams['font.family'] = 'sans-serif'\n    plt.rcParams[\"mathtext.default\"] = \"regular\"  # same as regular text\n    # other rcParams modifications...\n</code></pre>"},{"location":"06-Visualisation/#benefits","title":"Benefits","text":"<p>Centralising styling decisions in a one function yield key benefits:</p> <ol> <li>Consistency: All plots share the same visual style, creating a cohesive look and feel aligning with a chosen standards (e.g., tailored to a specific journal's style).</li> <li>Maintainability: Style changes can be made in one location rather than throughout the codebase.</li> </ol>"},{"location":"06-Visualisation/#design-advantages","title":"Design Advantages","text":"<p>Using this approach of seprate plotting functions and a style-setting function offers several advantages:</p> <ol> <li>Separation of concerns: Visualisation logic is separated from analysis code.</li> <li>Consistent styling: All plots have a cohesive style.</li> <li>Customisability: Functions accept optional figure and axes objects for further customization.</li> <li>Integration: Seamlessly integrates with the analysis workflow.</li> </ol> <p>This approach with independent plotting functions simplifies integration into the overall workflow and the GUI, which are discussed further in <code>08-Application-Workflow</code> and <code>07-GUI-Implementation</code>, respectively.\"</p>"},{"location":"07-GUI-Implementation/","title":"GUI Implementation for Time Lag Analysis","text":""},{"location":"07-GUI-Implementation/#overview","title":"Overview","text":"<p>This document outlines the implementation of the Graphical User Interface (GUI) in <code>app.py</code>. The GUI provides an interactive front-end for the time lag analysis workflow, allowing users to select data, input parameters, execute calculations, and visualise results. A snapshot is provided in Figure 1. It leverages the CustomTkinter library for modern UI elements and integrates Matplotlib for plotting.</p> <p></p> <p>Figure 1: Demonstration of the GUI.</p>"},{"location":"07-GUI-Implementation/#design-philosophy-and-structure","title":"Design Philosophy and Structure","text":"<p>The core design aims for clarity and ease of use, separating user inputs from results visualisation.</p> <ol> <li> <p>Framework choice: <code>customtkinter</code> is a modern UI-library based on Tkinter. It is selected for its modern appearance and theme support, providing a better user experience than standard Tkinter. <code>matplotlib</code> is used for its flexible plotting capabilities, integrated with <code>customtkinter</code> via <code>FigureCanvasTkAgg</code>.</p> </li> <li> <p>Layout strategy: The main application window (<code>App</code> class) utilises a <code>grid</code> layout. It's divided into three primary sections:</p> <ul> <li>Input panel (left): Contains all user controls (file selection, parameter entries, buttons) and the numerical results text box (<code>result_text</code>). This panel occupies less horizontal space.</li> <li>Plot panel (right): Dedicated to displaying the four key analysis plots. This panel is configured to expand significantly more than the input panel when the window is resized horizontally, ensuring ample space for visualisations.</li> <li>Footer (bottom): Displays static information (author, version) and does not expand vertically when the window is resized.</li> </ul> </li> </ol>"},{"location":"07-GUI-Implementation/#designing-customtkinter-elements","title":"Designing CustomTkinter Elements","text":"<p>In <code>customtkinter</code>, UI elements (or widgets) are typically instantiated as attributes of the main application class (e.g., <code>self.run_button = ctk.CTkButton(...)</code>).</p> <ul> <li>Appearance: Configured through parameters (e.g., <code>fg_color</code>, <code>font</code>, <code>width</code>) passed during creation or by calling the widget's <code>.configure()</code> method later.</li> <li>Behaviour: Defined by linking actions to events, often using the <code>command</code> parameter (for buttons, checkboxes, etc.) to specify a function to call, or by using the <code>.bind()</code> method for more general event handling.</li> </ul> <p>To position these elements within the window or within container widgets (like <code>CTkFrame</code>), layout managers such as <code>grid</code> or <code>pack</code> are used. For instance, <code>widget.grid(row=0, column=1, padx=5, pady=5, sticky='w')</code> places a widget in a specific row and column within its parent container, adding padding (<code>padx</code>, <code>pady</code>) for spacing, and controlling alignment (<code>sticky</code>). This application primarily uses the <code>grid</code> layout manager.</p>"},{"location":"07-GUI-Implementation/#gui-components-and-logic","title":"GUI Components and Logic","text":"<p>The following sections detail the specific widgets used, explaining their configuration and role within the application, following the principles outlined above.</p>"},{"location":"07-GUI-Implementation/#1-input-panel-input_frame","title":"1. Input Panel (<code>input_frame</code>)","text":"<p>This <code>CTkFrame</code> acts as a container, positioned using <code>grid</code> in the left column (column 0) and configured with <code>weight=1</code> for resizing. It houses the interactive elements for controlling the analysis:</p> <ul> <li> <p>File selection (<code>file_combobox</code>):</p> <ul> <li>A <code>CTkComboBox</code> widget, populated by scanning the <code>data_dir</code> (<code>get_xlxs_files</code>).</li> <li>Its <code>command</code> parameter is set to <code>on_combobox_selected</code>, triggering autofill logic when a new file is chosen.</li> <li>Positioned within the <code>input_frame</code> using <code>grid</code>.</li> </ul> </li> <li> <p>Parameter input (<code>d_cm_entry</code>, <code>L_cm_entry</code>, <code>qN2_mlmin_entry</code>):</p> <ul> <li>Standard <code>CTkEntry</code> widgets for essential experimental parameters. Their appearance (e.g., width) is set during instantiation.</li> <li>Default values are provided for convenience.</li> <li>Positioned using <code>grid</code>.</li> </ul> </li> <li> <p>Stabilisation time configuration:</p> <ul> <li>A <code>CTkCheckBox</code> (<code>use_custom_stab_time_checkbox</code>) allows switching between automatic detection (default) and manual input. Its <code>command</code> parameter links to <code>toggle_custom_stab_time_entries</code>.</li> <li>The <code>toggle_custom_stab_time_entries</code> method enables/disables the 'Start time' and 'End time' <code>CTkEntry</code> widgets (contained within a separate <code>CTkFrame</code>) based on the checkbox state, modifying their <code>state</code> configuration. Visual cues (graying out) indicate the disabled state.</li> <li>A <code>CTkLabel</code> (<code>help_label</code>) provides a tooltip (<code>show_tooltip</code>) explaining the auto-detection logic, using event binding (<code>bind</code>) for hover detection.</li> <li>All elements are positioned using <code>grid</code>.</li> </ul> </li> <li> <p>Execution (<code>run_button</code>):</p> <ul> <li>A <code>CTkButton</code> whose <code>command</code> parameter is linked to the main <code>run_analysis</code> method.</li> <li>Positioned using <code>grid</code>.</li> </ul> </li> <li> <p>Results display (<code>result_text</code>):</p> <ul> <li>A <code>CTkTextbox</code> used to display formatted numerical results. Its content is updated programmatically within <code>perform_calculations</code>.</li> <li>Positioned using <code>grid</code>.</li> </ul> </li> <li> <p>Scaling controls (<code>scaling_combobox</code>, <code>label_scaling_combobox</code>):</p> <ul> <li><code>CTkComboBox</code> widgets allowing users to adjust UI and plot label scaling.</li> <li>Their <code>command</code> parameters link to <code>change_scaling</code> and <code>change_label_scaling</code> respectively.</li> <li>Positioned using <code>grid</code>.</li> </ul> </li> </ul>"},{"location":"07-GUI-Implementation/#2-plot-panel-plot_frame","title":"2. Plot Panel (<code>plot_frame</code>)","text":"<p>This <code>CTkFrame</code> displays the graphical results, positioned using <code>grid</code> in the right column (column 1) and configured with <code>weight=4</code>. This higher weight (compared to the Input Panel with <code>weight=1</code>) ensures it expands more significantly than the input panel during horizontal resizing:</p> <ul> <li>Plot integration: <code>matplotlib</code> figures are embedded within individual <code>CTkFrame</code> widgets using <code>FigureCanvasTkAgg</code>. The canvas widget obtained from <code>FigureCanvasTkAgg</code> is then positioned using <code>grid</code> within its container frame.</li> <li>Layout: The container frames for each plot are arranged in a 2x2 layout within the main <code>plot_frame</code> using <code>grid</code>.</li> <li>Plot Generation: Plots are created by functions in <code>visualisation.py</code> (e.g., <code>plot_time_lag_analysis</code>) using data stored in <code>self.calculation_results</code>. The <code>update_plots</code> method handles embedding these figures.</li> <li>Interactivity: Each plot's container frame includes a 'Save' <code>CTkButton</code>. Its <code>command</code> is configured (using a <code>lambda</code> function to pass the specific figure) to open a file dialog (<code>ctk.filedialog.asksaveasfilename</code>) for exporting the corresponding figure.</li> </ul>"},{"location":"07-GUI-Implementation/#3-core-interaction-workflow-run_analysis","title":"3. Core Interaction Workflow (<code>run_analysis</code>)","text":"<p>The <code>run_analysis</code> method orchestrates the main application flow, triggered by the <code>run_button</code>:</p> <ol> <li> <p>Trigger: Initiated by the \"Run Analysis\" button's <code>command</code>.</p> </li> <li> <p>Calculation (<code>perform_calculations</code>):</p> <ul> <li>Retrieves input values (file path, parameters, stabilisation time choice) from the UI widgets using their <code>.get()</code> methods.</li> <li>Performs basic validation.</li> <li>Calls the backend <code>time_lag_analysis_workflow</code> function from <code>time_lag_analysis.py</code> (detailed in <code>08-Application-Workflow</code>).</li> <li>Stores the returned results in <code>self.calculation_results</code>.</li> <li>Formats and displays numerical results in the <code>result_text</code> box by configuring its content.</li> </ul> </li> <li> <p>Plotting (<code>update_plots</code>):</p> <ul> <li>Called after <code>perform_calculations</code> or when plot label scaling changes (via <code>label_scaling_combobox</code> command).</li> <li>Clears any existing plots from the <code>plot_frame</code>.</li> <li>Generates the four plots using data from <code>self.calculation_results</code>.</li> <li>Applies the current label scaling factor.</li> <li>Embeds each plot figure and its associated 'Save' button into the <code>plot_frame</code> using <code>grid</code>.</li> </ul> </li> </ol> <p>This structure ensures that calculations are performed first, and the results are then used to update both the numerical display and the graphical plots by configuring the relevant widgets.</p>"},{"location":"07-GUI-Implementation/#data-flow-within-the-application","title":"Data Flow within the Application","text":"<p>The GUI facilitates a clear flow of data from user input to final results:</p> <ol> <li> <p>User input collection: When <code>run_analysis</code> is triggered, values are read directly from UI widgets:</p> <ul> <li><code>self.file_combobox.get()</code> -&gt; Selected data file path.</li> <li><code>self.d_cm_entry.get()</code>, <code>self.L_cm_entry.get()</code>, <code>self.qN2_mlmin_entry.get()</code> -&gt; Experimental parameters (converted to floats).</li> <li><code>self.checkbox_var.get()</code> -&gt; Determines stabilisation time mode (auto/manual).</li> <li><code>self.stab_time_start_entry.get()</code>, <code>self.stab_time_end_entry.get()</code> -&gt; Custom time range (if manual mode).</li> </ul> </li> <li> <p>Backend processing (<code>perform_calculations</code>):</p> <ul> <li>The collected inputs are passed to <code>time_lag_analysis_workflow</code> (from <code>time_lag_analysis.py</code>).</li> <li>This function performs the core scientific calculations (data loading, processing, regression, parameter calculation).</li> <li>It returns a dictionary (<code>results_dict</code>) containing numerical results and potentially pandas DataFrames.</li> </ul> </li> <li> <p>Result storage: The returned <code>results_dict</code> is stored in the application's state variable <code>self.calculation_results</code>.</p> </li> <li> <p>Output display:</p> <ul> <li>Numerical: <code>perform_calculations</code> formats key values from <code>self.calculation_results</code> into a string and updates the <code>self.result_text</code> widget.</li> <li>Graphical (<code>update_plots</code>): The <code>update_plots</code> function accesses <code>self.calculation_results</code> (specifically the DataFrames and calculated parameters) and passes them to the plotting functions in <code>visualisation.py</code>. The generated <code>matplotlib</code> figures are then displayed in the <code>plot_frame</code>.</li> </ul> </li> </ol> <p>This flow ensures separation between the UI layer and the calculation logic, with <code>self.calculation_results</code> acting as the bridge.</p>"},{"location":"08-Application-Workflow/","title":"Application Workflow","text":"<p>This document explains how the components of the Time Lag Analysis application integrate into a cohesive workflow for analysing gas permeation through membranes.</p>"},{"location":"08-Application-Workflow/#the-central-workflow-function","title":"The Central Workflow Function","text":""},{"location":"08-Application-Workflow/#workflow-overview","title":"Workflow Overview","text":"<p>The application combines data processing, time lag analysis, PDE solving, and visualisation via the <code>time_lag_analysis_workflow</code> function in <code>time_lag_analysis.py</code>, creating a single and streamlined process. </p> <p>The <code>time_lag_analysis_workflow</code> function takes the following key parameters:</p> <ul> <li><code>datapath</code>: Path to experimental data file</li> <li><code>L_cm</code>: Membrane thickness</li> <li><code>d_cm</code>: Membrane diameter</li> <li><code>stabilisation_time_range</code>: Optional steady-state time range</li> <li><code>display_plot</code>/<code>save_plot</code>/<code>save_data</code>: Output options</li> </ul>"},{"location":"08-Application-Workflow/#workflow-structure","title":"Workflow Structure","text":"<p>The diagram below illustrates the interaction between the components inside the main <code>time_lag_analysis_workflow</code>:</p> <pre><code>graph TD\n    A[Data Processing Module] --&gt; B[Time Lag Analysis];\n    B --&gt; C[PDE Numerical Solution];\n    A --&gt; D[Visualisation Layer];\n    B --&gt; D;\n    C --&gt; D;\n    D --&gt; E[Results and Output Files];\n</code></pre>"},{"location":"08-Application-Workflow/#core-workflow-stages","title":"Core Workflow Stages","text":"<p>The <code>time_lag_analysis_workflow</code> encompasses the following stages:</p> <ol> <li>Data Processing: Import and prepare experimental data.</li> <li>Time Lag Analysis: Calculate transport parameters from steady-state data.</li> <li>PDE Solution: Simulate theoretical concentration profile.</li> <li>Visualisation: Create plots comparing experimental and theoretical results.</li> <li>Results: Store calculated parameters and processed data.</li> </ol>"},{"location":"08-Application-Workflow/#component-functions","title":"Component Functions","text":"<p>The main stages in <code>time_lag_analysis_workflow</code> consist of the following functions:</p> <ul> <li>Data Processing: <code>load_data</code>, <code>preprocess_data</code>, <code>identify_stabilisation_time</code> from <code>data_processing.py</code>.</li> <li>Time Lag Analysis: <code>time_lag_analysis</code> from <code>calculations.py</code>.</li> <li>PDE Solution: <code>solve_constant_diffusivity_model</code> from <code>calculations.py</code>.</li> <li>Visualisation: <code>plot_time_lag_analysis</code>, <code>plot_flux_over_time</code>, <code>plot_concentration_profile</code> from <code>visualisation.py</code>.</li> </ul>"},{"location":"08-Application-Workflow/#workflow-data-flow","title":"Workflow Data Flow","text":"<p>The components within the <code>time_lag_analysis_workflow</code> exchange data as follows:</p> <ol> <li> <p>Data Processing \u2192 Time Lag Analysis</p> </li> <li> <p>Processed experimental data with flux values, stabilisation time, and normalised measurements.</p> </li> <li> <p>Time Lag Analysis \u2192 PDE Solution</p> </li> <li> <p>Calculated diffusion coefficient, equilibrium concentration, and membrane thickness.</p> </li> <li> <p>All Modules \u2192 Visualisation</p> </li> <li> <p>Experimental data, transport parameters, and theoretical profiles.</p> </li> </ol>"},{"location":"08-Application-Workflow/#workflow-benefits","title":"Workflow Benefits","text":"<p>Abstracting all implementation into a streamlined workflow yields the following benefits:</p> <ul> <li>Reproducibility: Complete analysis with a single function call.</li> <li>Consistency: Standardised processing pipeline.</li> <li>Validation: Automatic comparison of theory with experiment.</li> <li>Modularity: Easy to extend with new components.</li> </ul> <p>The benefits of this end-to-end workflow are most apparent when building a GUI, which is detailed in <code>07-GUI-Implementation</code>.</p>"},{"location":"09-Exercises-and-Best-Practices/","title":"Exercises and Best Practices","text":""},{"location":"09-Exercises-and-Best-Practices/#overview","title":"Overview","text":"<p>This document provides exercises to reinforce the concepts covered in the previous sections and offers best practices for extending or adapting this application to your own research. The exercises assume familiarity with the core implementation details discussed in sections <code>03-Data-Management-and-Processing.md</code> through <code>08-Application-Workflow.md</code>.</p>"},{"location":"09-Exercises-and-Best-Practices/#exercises","title":"Exercises","text":"<p>These exercises are designed to help you understand the application's components and explore its capabilities. They primarily focus on teaching best practices that are fundamental in building data pipelines, regardless of the specific domain. They are arranged from easiest to hardest, and it is recommended to work through them in order.</p>"},{"location":"09-Exercises-and-Best-Practices/#1-flexible-data-file-loading","title":"1. Flexible Data File Loading","text":"<ul> <li>Context: The current <code>load_data</code> function in <code>data_processing.py</code> assumes the input file is a standard comma-separated CSV with a specific header row. Real-world data often varies in delimiters (commas, tabs, semicolons) and may have different header configurations or starting rows.</li> <li>Goal: Enhance the robustness of data loading to accommodate common variations in CSV file formats.</li> <li>Task: Modify the <code>load_data</code> function to automatically detect or allow the user to specify the delimiter used in the input CSV file. Additionally, handle potential variations in header presence or starting row for data.</li> <li>Hint: Explore the <code>delimiter</code> and <code>header</code> arguments in <code>pandas.read_csv</code>. Consider adding <code>try-except</code> blocks to attempt loading with different delimiters if the initial attempt fails.</li> </ul>"},{"location":"09-Exercises-and-Best-Practices/#2-handling-missing-data-points","title":"2. Handling Missing Data Points","text":"<ul> <li>Context: The current analysis assumes complete datasets. Experimental data frequently contains missing values (NaNs), possibly due to sensor errors or data logging issues, which can cause errors in calculations.</li> <li>Goal: Implement strategies for dealing with missing numerical values within the time or flux data columns.</li> <li>Task: Update the data processing steps (likely within or after <code>load_data</code> in <code>data_processing.py</code>) to identify and handle rows where time or flux values might be missing. Implement at least one handling strategy (e.g., removing the row, linear interpolation).</li> <li>Hint: Use <code>isna</code>, <code>dropna</code>, or <code>interpolate</code> methods within <code>pandas.DataFrame</code>. Consider logging a warning message when missing data is detected and handled, and think about how each strategy might affect the results.</li> </ul>"},{"location":"09-Exercises-and-Best-Practices/#3-robust-column-identification","title":"3. Robust Column Identification","text":"<ul> <li>Context: The code currently expects specific column names (<code>'t / s'</code>, <code>'cumulative flux / cm^3(STP) cm^-2'</code>). Data files from different instruments or labs often use different naming conventions (e.g., <code>'Time'</code>, <code>'Flux (cc/m2)'</code>).</li> <li>Goal: Make the analysis less dependent on exact column names in the input file.</li> <li>Task: Modify the data loading or processing logic in <code>data_processing.py</code> to allow for variations in column names for time and flux. Implement a way to identify the correct columns, such as  by searching for keywords or allowing the user to specify the names, and map them to the internal standard names.</li> <li>Hint: You could check <code>df.columns</code> after loading and use <code>df.rename</code> to standardise them. Consider using regular expressions or simple string matching (<code>.str.contains()</code>) to find potential column names.</li> </ul>"},{"location":"09-Exercises-and-Best-Practices/#4-input-file-validation","title":"4. Input File Validation","text":"<ul> <li>Context: Currently, errors related to incorrect file structure (e.g., missing required columns, non-numeric data in expected numeric columns) might only appear later during calculations, leading to potentially confusing error messages.</li> <li>Goal: Prevent errors later in the analysis by validating the input file structure early after loading.</li> <li>Task: Add checks within <code>load_data</code> in <code>data_processing.py</code> or immediately after, to verify that the loaded DataFrame contains the necessary columns (time and flux, after handling potential name variations from Exercise 3) and that these columns contain numeric data. Raise informative errors if the validation fails.</li> <li>Hint: Check <code>df.columns</code> against expected columns. Use <code>df.dtypes</code> to check data types, and consider using <code>pd.to_numeric</code> with <code>errors='coerce'</code> followed by <code>.isna().any()</code> to detect non-numeric entries in numeric columns.</li> </ul>"},{"location":"09-Exercises-and-Best-Practices/#5-batch-processing-with-error-reporting","title":"5. Batch Processing with Error Reporting","text":"<ul> <li>Context: The current GUI workflow processes only one file at a time. It is often handy to analyse multiple experimental runs efficiently. Running them individually is time-consuming, and a single problematic file could halt the entire process if not handled correctly.</li> <li>Goal: Enable efficient analysis of multiple datasets while gracefully handling problematic files.</li> <li>Task: Create a new function or modify the main analysis workflow (<code>run_analysis</code> or its caller in <code>gui.py</code>) to accept a list of input file paths. Loop through the files, attempting the full analysis for each. If a file causes an error, catch the specific exception, log the error and the problematic filename, and continue with the next file. Collect and present results only for successfully processed files.</li> <li>Hint: Use a <code>for</code> loop over the list of file paths. Wrap the analysis call for a single file inside a <code>try...except</code> block (e.g., <code>except (FileNotFoundError, ValueError, KeyError) as e:</code>). Store successful results in a list or dictionary, and perhaps maintain a separate list for files that caused errors.</li> </ul>"},{"location":"09-Exercises-and-Best-Practices/#best-practices-for-extension-and-adaptation","title":"Best Practices for Extension and Adaptation","text":"<p>The following practices offer guidance for adapting this code for your research applications. They are intended as a foundation to help you build a first prototype based on this exemplar, rather than an exhaustive list.</p>"},{"location":"09-Exercises-and-Best-Practices/#1-modularity-and-code-structure","title":"1. Modularity and Code Structure","text":"<ul> <li>Keep components separate: Maintain the separation between data processing, core calculations, PDE solving, and the user interface. This makes the code easier to understand, test, and modify.</li> <li>Use functions effectively: Break down complex tasks into smaller, reusable functions with clear purposes, as demonstrated by the helper functions (<code>_setup_grid</code>, <code>_calculate_flux</code>, etc.).</li> <li>Object-Oriented Programming (OOP): For more complex applications, consider using classes to encapsulate data and related functionality (e.g., a <code>MembraneSimulation</code> class).</li> </ul>"},{"location":"09-Exercises-and-Best-Practices/#2-numerical-methods-and-validation","title":"2. Numerical Methods and Validation","text":"<ul> <li>Understand solver limitations: Be aware of the assumptions and limitations of the chosen numerical methods (e.g., Method of Lines, BDF solver). It is best to consult the SciPy documentation for <code>solve_ivp</code> and other solvers, including <code>ode_int</code>, to choose the best option for your applications.</li> <li>Grid independence study: Verify that the numerical solution (concentration profile, flux) does not significantly change when refining the spatial (<code>dx</code>) and temporal (<code>dt</code>) discretisation.</li> <li>Parameter sensitivity: Analyse how sensitive the results are to input parameters (e.g., <code>rtol</code>, <code>atol</code>, <code>diffusion_coeff</code>).</li> <li>Validate against known solutions: Whenever possible, test your implementation against analytical solutions or results from literature for simplified cases.</li> </ul>"},{"location":"09-Exercises-and-Best-Practices/#3-data-handling-and-management","title":"3. Data Handling and Management","text":"<ul> <li>Input validation: Add checks to ensure input data (from files or GUI) is in the expected format and range.</li> <li>Clear units: Consistently track and document units throughout the calculations, as done in the variable names and comments in <code>calculations.py</code>.</li> <li>Data provenance: Keep records of the raw data, processing steps, and software versions used to generate results.</li> </ul>"},{"location":"09-Exercises-and-Best-Practices/#acknowledgements-and-closing-remarks","title":"Acknowledgements and Closing Remarks","text":"<p>We appreciate you taking the time to work through this exemplar. This was made possible by the relentless support of the ReCoDe team at Imperial. It was a rewarding project to create, and we hope you found the experience equally enjoyable and valuable.</p> <p>Code on and never stop learning!</p> <p>Best regards,</p> <p>Louis and the ReCoDe team</p>"}]}